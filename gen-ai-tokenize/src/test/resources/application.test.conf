bpe {
  # Vocabulary settings
  vocab {
    # File encoding for the input text
    encoding = "ISO-8859-1"
  
    # Maximum size of the initial vocabulary (number of unique token IDs)
    max-size = 256

    # Maximum number of BPE merges to perform
    max-merges = 10000
    
    # Seperator used to indicate merges
    merge-separator = "_"
    
    # Identifier to handle UnKnown tokens
    unk-token = "<unk>"
  }

  # Input characters used for generating the initial vocabulary
  input-chars = "abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789 "

  # Tokenization options
  tokenization {
    # Minimum frequency for merging pairs
    min-pair-frequency = 2

    # Whether to treat whitespace as a separate token
    include-whitespace = true
  }

  # File paths (optional)
  files {
    # Where to save the vocabulary
    vocab-file = "data/vocab.json"

    # Where to save the merges list
    merges-file = "data/merges.txt"

    # Path to the input text file for training
    input-file = "data/input.txt"
  }
}
